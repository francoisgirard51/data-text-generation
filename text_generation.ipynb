{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Text generation using a RNN ‚úçÔ∏è "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Our goal is to use a dataset of Shakespeare's writing from http://karpathy.github.io/2015/05/21/rnn-effectiveness/ in order to generate Shakespeare like texts from our own prompts! **Our model will take in 100 characters and predict the 101st character.** To predict an entire paragraph we can call our model over and over again using our generated characters (i.e character 2-100 + our generated 101 to predict 102)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "### 1.1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:11.935727Z",
     "iopub.status.busy": "2022-12-14T13:32:11.935518Z",
     "iopub.status.idle": "2022-12-14T13:32:13.873227Z",
     "shell.execute_reply": "2022-12-14T13:32:13.872259Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 17:07:08.383025: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "### 1.2) Get the data üìï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the helper function below üëá you can see it downloads us the data in the filename **shakespeare.txt** and returns us the file path to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:13.877626Z",
     "iopub.status.busy": "2022-12-14T13:32:13.876904Z",
     "iopub.status.idle": "2022-12-14T13:32:13.931441Z",
     "shell.execute_reply": "2022-12-14T13:32:13.930866Z"
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_data = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "### 1.3) Have a look at the data üîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can open the file and read it as a string (we have to decode it to make a string rather than a byte string): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:13.934985Z",
     "iopub.status.busy": "2022-12-14T13:32:13.934481Z",
     "iopub.status.idle": "2022-12-14T13:32:13.939701Z",
     "shell.execute_reply": "2022-12-14T13:32:13.939141Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_data, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:13.942844Z",
     "iopub.status.busy": "2022-12-14T13:32:13.942304Z",
     "iopub.status.idle": "2022-12-14T13:32:13.945817Z",
     "shell.execute_reply": "2022-12-14T13:32:13.945271Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## 2Ô∏è‚É£ Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### 2.1) Vectorize the text\n",
    "\n",
    "Before training, you need to convert the strings to a numerical representation. \n",
    "\n",
    "The [tf.keras.layers.StringLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) layer can convert each character into a numeric ID. This layer just needs the text to be split into tokens first. You can use the helper function [tf.strings.unicode_split](https://www.tensorflow.org/api_docs/python/tf/strings/unicode_split) to achieve that like the example below üëá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:13.966911Z",
     "iopub.status.busy": "2022-12-14T13:32:13.966697Z",
     "iopub.status.idle": "2022-12-14T13:32:17.404330Z",
     "shell.execute_reply": "2022-12-14T13:32:17.403658Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 17:07:18.590858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Generate the vocab üìñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Generate a list of **unique characters** in our text and save it in the variable **`vocab`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s4f1q3iqY8f"
   },
   "source": [
    "‚ùì Now create the `tf.keras.layers.StringLookup` layer and save it as `ids_from_chars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.408060Z",
     "iopub.status.busy": "2022-12-14T13:32:17.407548Z",
     "iopub.status.idle": "2022-12-14T13:32:17.423673Z",
     "shell.execute_reply": "2022-12-14T13:32:17.423064Z"
    },
    "id": "6GMlCe3qzaL9",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=vocab, mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary markdown='span'>üí° If you get stuck</summary>\n",
    "\n",
    "```python\n",
    "tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmX_jbgQqfOi"
   },
   "source": [
    "It converts from tokens to character IDs based on the vocab we passed to it. \n",
    "\n",
    "‚ùì Use the layer below üëá and edit `chars` variable above and see what happens when you add characters outside the vocab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.427404Z",
     "iopub.status.busy": "2022-12-14T13:32:17.426909Z",
     "iopub.status.idle": "2022-12-14T13:32:17.434684Z",
     "shell.execute_reply": "2022-12-14T13:32:17.434039Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "To generate text, it will also be important to **invert this representation** and recover human-readable strings from it. For this you can use `tf.keras.layers.StringLookup(..., invert=True)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uenivzwqsDhp"
   },
   "source": [
    "‚ùóÔ∏è Here instead of passing the original vocabulary generated with `sorted(set(text))`, use the `get_vocabulary()` method of the `tf.keras.layers.StringLookup` to get the vocabulary assigned to the previous `ids_from_chars` layer. \n",
    "\n",
    "This way, we also have a `[UNK]` string for unknown characters outside our original representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.438253Z",
     "iopub.status.busy": "2022-12-14T13:32:17.437740Z",
     "iopub.status.idle": "2022-12-14T13:32:17.449424Z",
     "shell.execute_reply": "2022-12-14T13:32:17.448738Z"
    },
    "id": "Wd2m3mqkDjRj"
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqTDDxS-s-H8"
   },
   "source": [
    "This layer recovers the characters from the vectors of IDs, and returns them as a `tf.RaggedTensor` of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.452733Z",
     "iopub.status.busy": "2022-12-14T13:32:17.452253Z",
     "iopub.status.idle": "2022-12-14T13:32:17.457574Z",
     "shell.execute_reply": "2022-12-14T13:32:17.456992Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FeW5gqutT3o"
   },
   "source": [
    "‚úçÔ∏è We use `tf.strings.reduce_join` to join the characters back into strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.461040Z",
     "iopub.status.busy": "2022-12-14T13:32:17.460453Z",
     "iopub.status.idle": "2022-12-14T13:32:17.506637Z",
     "shell.execute_reply": "2022-12-14T13:32:17.505960Z"
    },
    "id": "zxYI-PeltqKP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Define a function `text_from_ids` that takes a tensor of ids and returns the corresponding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.509989Z",
     "iopub.status.busy": "2022-12-14T13:32:17.509440Z",
     "iopub.status.idle": "2022-12-14T13:32:17.512781Z",
     "shell.execute_reply": "2022-12-14T13:32:17.512180Z"
    },
    "id": "w5apvBDn9Ind",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Run the **test** below to check you are able to go back and forth from **text -> ids -> text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/06-Deep-Learning/04-RNN-and-NLP/data-text-generation/tests\n",
      "plugins: dash-2.14.1, asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_helpers.py::TestHelpers::test_chars_to_ids \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 50%]\u001b[0m\n",
      "test_helpers.py::TestHelpers::test_ids_to_chars \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/helpers.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed helpers step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "test_texts = ['LeWagon', 'NLP`']\n",
    "test_chars = tf.strings.unicode_split(test_texts, input_encoding='UTF-8')\n",
    "test_ids = ids_from_chars(test_chars)\n",
    "test_reverse = text_from_ids(test_ids)\n",
    "result = ChallengeResult('helpers', ids=list(test_ids[0].numpy()), chars=test_reverse[1].numpy())\n",
    "result.write(); print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) The dataset üöö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì First split our whole text using `unicode_split` and convert them all with `ids_from_chars`, to get all of our text as a single continuous array saved as `all_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.516290Z",
     "iopub.status.busy": "2022-12-14T13:32:17.515731Z",
     "iopub.status.idle": "2022-12-14T13:32:17.862389Z",
     "shell.execute_reply": "2022-12-14T13:32:17.861710Z"
    },
    "id": "UopbsKi88tm5",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then make a tensorflow dataset object with that array. This is an object which allows us to write pipelines to transform our data into the format needed for our model to read it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.866209Z",
     "iopub.status.busy": "2022-12-14T13:32:17.865672Z",
     "iopub.status.idle": "2022-12-14T13:32:17.870573Z",
     "shell.execute_reply": "2022-12-14T13:32:17.869940Z"
    },
    "id": "qmxrYDCTy-eL"
   },
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The `batch` method allows us to set how many characters we should take at a time! In our case we want **101**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.909371Z",
     "iopub.status.busy": "2022-12-14T13:32:17.908760Z",
     "iopub.status.idle": "2022-12-14T13:32:17.926465Z",
     "shell.execute_reply": "2022-12-14T13:32:17.925781Z"
    },
    "id": "BpdjRO2CzOfZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(101, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PHW902-4oZt"
   },
   "source": [
    "It's easier to see  if we join the tokens back into strings üëá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.929732Z",
     "iopub.status.busy": "2022-12-14T13:32:17.929193Z",
     "iopub.status.idle": "2022-12-14T13:32:17.944697Z",
     "shell.execute_reply": "2022-12-14T13:32:17.943979Z"
    },
    "id": "QO32cMWu4a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "For training you'll need a dataset of `(input, label)` pairs, where `input` and \n",
    "`label` are sequences. \n",
    "\n",
    "Even though we are predicting one character at a time, the sequence at each time step consists of the:\n",
    "\n",
    "1. `input` which is the `n` characters in the sequence up to the `n+1` character we want to predict\n",
    "2. `label` which is the predicted character and `n-1` characters leading up to it.\n",
    "\n",
    "For example if the text is `\"Hello\"`. The input sequence would be `\"Hell\"`, and the target sequence `\"ello\"`.\n",
    "\n",
    "</br>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ü§î Why do we have a target of <strong>ello</strong> if our goal is only to predict <strong>o</strong>? Click here for an explanation.</summary>\n",
    "\n",
    "It is much more stable to train a model this way. If **H** was only updated by the back propagation from the predict of **o** it would be very weakly updated. This problem would be even worse with 100 characters between!\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "‚ùì Write a function `split_input_target` which converts a sequence to a `(input, label)` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.947952Z",
     "iopub.status.busy": "2022-12-14T13:32:17.947412Z",
     "iopub.status.idle": "2022-12-14T13:32:17.950819Z",
     "shell.execute_reply": "2022-12-14T13:32:17.950262Z"
    },
    "id": "9NGu-FkO_kYU",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we map the function to our dataset. This applies it to every element in the dataset, this is part of the reason `tensorflow` datasets are so powerful for preprocessing data! üôå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:17.960675Z",
     "iopub.status.busy": "2022-12-14T13:32:17.960150Z",
     "iopub.status.idle": "2022-12-14T13:32:17.998126Z",
     "shell.execute_reply": "2022-12-14T13:32:17.997551Z"
    },
    "id": "B9iKPXkw5xwa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout what our **`dataset`** looks like now üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:18.001470Z",
     "iopub.status.busy": "2022-12-14T13:32:18.000984Z",
     "iopub.status.idle": "2022-12-14T13:32:18.026512Z",
     "shell.execute_reply": "2022-12-14T13:32:18.025795Z"
    },
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### 2.4) Optimizing the dataset üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tensorflow [datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) we define the batch size before we fit the model. We also:\n",
    "\n",
    "- shuffle the dataset\n",
    "- prefetch (this gets the next N elements ready) - super important when we are loading data from disk to have it ready for the next batch without wasting GPU time! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:18.029784Z",
     "iopub.status.busy": "2022-12-14T13:32:18.029273Z",
     "iopub.status.idle": "2022-12-14T13:32:18.039620Z",
     "shell.execute_reply": "2022-12-14T13:32:18.039073Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Run the **test** below to check you have a working dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/06-Deep-Learning/04-RNN-and-NLP/data-text-generation/tests\n",
      "plugins: dash-2.14.1, asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_dataset.py::TestDataset::test_input_shape \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 50%]\u001b[0m\n",
      "test_dataset.py::TestDataset::test_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/dataset.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed dataset step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('dataset', input_shape=tuple(dataset.element_spec[0].shape), output_shape=tuple(dataset.element_spec[1].shape))\n",
    "result.write(); print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 3Ô∏è‚É£ Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Define the model üîÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "This section defines the model as a [`keras.Model`](https://keras.io/api/models/model/) subclass which you won't have seen before (For details see [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
    "\n",
    "This model has three layers:\n",
    "\n",
    "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
    "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
    "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì The **model** is quite different than how we have defined models so far. Take a few minutes to try and understand the code. \n",
    "\n",
    "- The first section is the `__init__` here we define layers using `self.layer_name = layer`\n",
    "- The second section is where we define how to use the layers when we are given an input. You can see we call the layers similarly to the [Keras functional API](https://keras.io/guides/functional_api/) but we the flexibility to include `if` statements and other code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:18.049811Z",
     "iopub.status.busy": "2022-12-14T13:32:18.049307Z",
     "iopub.status.idle": "2022-12-14T13:32:18.054723Z",
     "shell.execute_reply": "2022-12-14T13:32:18.054087Z"
    },
    "id": "wj8HQ2w8z4iO"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, 256)\n",
    "        self.gru = tf.keras.layers.GRU(1024,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:18.057787Z",
     "iopub.status.busy": "2022-12-14T13:32:18.057286Z",
     "iopub.status.idle": "2022-12-14T13:32:18.071762Z",
     "shell.execute_reply": "2022-12-14T13:32:18.071185Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "model = MyModel(vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "‚ùóÔ∏è For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "### 3.2) Check the model üî¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call the untrained model of our first piece of data üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:18.075434Z",
     "iopub.status.busy": "2022-12-14T13:32:18.074933Z",
     "iopub.status.idle": "2022-12-14T13:32:20.720603Z",
     "shell.execute_reply": "2022-12-14T13:32:20.719812Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "To get actual predictions from the model you need to sample from the output distributions. \n",
    "\n",
    "- This distribution is defined by the logits over the character vocabulary.\n",
    "- ‚ùó It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
    "\n",
    "Try it for the first example in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:20.741781Z",
     "iopub.status.busy": "2022-12-14T13:32:20.741240Z",
     "iopub.status.idle": "2022-12-14T13:32:20.747723Z",
     "shell.execute_reply": "2022-12-14T13:32:20.747167Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "This gives us, at each timestep, a prediction of the next character index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:20.751122Z",
     "iopub.status.busy": "2022-12-14T13:32:20.750595Z",
     "iopub.status.idle": "2022-12-14T13:32:20.754941Z",
     "shell.execute_reply": "2022-12-14T13:32:20.754313Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 23, 25, 64,  5, 45,  4,  5, 22,  4, 57, 46, 45, 33, 11, 31, 60,\n",
       "       12, 31, 42, 25, 15, 37, 60, 24, 47, 48, 18, 19, 26, 24, 49, 64,  5,\n",
       "       53, 31, 11, 40, 53, 51, 52, 16, 14,  0, 57, 26, 57, 23, 33, 37, 31,\n",
       "       43, 42, 18, 62,  9, 53, 45, 49, 21, 40, 34,  7, 63, 65, 38, 27, 51,\n",
       "       17, 25, 25, 46, 33, 57, 59, 11, 12, 13, 25, 26, 26,  8, 47, 38, 19,\n",
       "       11, 35, 38,  9, 46, 37, 43, 26, 22, 35, 55, 60, 11, 64,  2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "### 3.3) Train the model üèãÔ∏è‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "‚ùì Compile the model with the **correct loss** and an optimizer\n",
    "\n",
    "</br>\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>üí° Click here for the loss if you're stuck</summary>\n",
    "\n",
    "    You should use the <code>tf.keras.losses.SparseCategoricalCrossentropy</code> loss.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:20.796150Z",
     "iopub.status.busy": "2022-12-14T13:32:20.795668Z",
     "iopub.status.idle": "2022-12-14T13:32:20.913410Z",
     "shell.execute_reply": "2022-12-14T13:32:20.912716Z"
    },
    "id": "DDl1_Een6rL0",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Run the **test** below to check you have a good model before beginning to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/06-Deep-Learning/04-RNN-and-NLP/data-text-generation/tests\n",
      "plugins: dash-2.14.1, asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_model.py::TestModel::test_loss \u001b[32mPASSED\u001b[0m\u001b[33m                               [ 50%]\u001b[0m\n",
      "test_model.py::TestModel::test_output \u001b[32mPASSED\u001b[0m\u001b[33m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:43\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:43: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:73\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:73: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:80\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:80: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:66\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:66: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _TENSORSHAPEPROTO = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:19\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:33\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:37\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:37: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:41\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:41: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:45\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:45: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:49\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:49: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:53\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:53: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:57\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:57: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:61\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:61: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:65\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:65: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:69\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:69: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:73\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:73: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:77\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:77: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:81\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:81: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:85\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:85: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:89\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:89: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:93\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:93: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:97\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:97: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:101\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:101: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:105\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:105: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:109\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:109: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:113\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:113: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:117\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:117: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:121\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:121: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:125\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:125: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:129\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:129: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:133\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:133: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:137\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:137: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:141\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:141: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:145\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:145: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:149\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:149: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:153\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:153: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:157\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:157: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:161\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:161: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:165\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:165: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:169\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:169: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:173\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:173: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:177\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:177: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:181\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:181: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:185\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:185: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:189\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:189: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:193\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:193: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:197\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:197: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:201\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:201: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:205\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:205: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:209\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:209: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:213\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:213: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:217\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:217: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.EnumValueDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:27\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:287\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:280\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:46\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:46: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:76\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:76: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:83\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:83: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:90\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:90: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:97\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:97: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:104\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:104: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:111\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:111: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:69\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:69: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _RESOURCEHANDLEPROTO = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:21\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:40\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:47\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:47: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:54\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:54: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:61\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:61: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:68\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:68: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:75\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:75: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:82\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:82: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:89\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:89: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:96\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:96: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:103\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:103: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:110\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:110: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:117\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:117: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:124\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:124: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:131\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:131: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:138\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:138: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:145\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:145: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:152\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:152: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:33\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _TENSORPROTO = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:183\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:183: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:190\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:190: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:197\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:197: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:176\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:176: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _VARIANTTENSORDATAPROTO = _descriptor.Descriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:21\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:40\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:47\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:47: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:54\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:54: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:61\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:61: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:68\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:68: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:75\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:75: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "../../../../../../.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:82\n",
      "  /Users/francoisgirard/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:82: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "    _descriptor.FieldDescriptor(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m======================= \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m100 warnings\u001b[0m\u001b[33m in 6.60s\u001b[0m\u001b[33m ========================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('model', loss=type(model.loss), output_weights=model.trainable_weights[5].shape[0])\n",
    "result.write(); print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "To keep training within reasonable time, we will use **just 5 epochs** (you can increase this later if you like) to train the model. \n",
    "\n",
    "This will still take about 10 mins so grab a coffee ‚òïÔ∏è while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:20.930017Z",
     "iopub.status.busy": "2022-12-14T13:32:20.929797Z",
     "iopub.status.idle": "2022-12-14T13:34:54.171315Z",
     "shell.execute_reply": "2022-12-14T13:34:54.170464Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "172/172 [==============================] - 348s 2s/step - loss: 2.7321\n",
      "Epoch 2/5\n",
      "172/172 [==============================] - 331s 2s/step - loss: 1.9928\n",
      "Epoch 3/5\n",
      "172/172 [==============================] - 324s 2s/step - loss: 1.7159\n",
      "Epoch 4/5\n",
      "172/172 [==============================] - 334s 2s/step - loss: 1.5549\n",
      "Epoch 5/5\n",
      "172/172 [==============================] - 326s 2s/step - loss: 1.4564\n",
      "CPU times: user 1h 23min 42s, sys: 7min 29s, total: 1h 31min 12s\n",
      "Wall time: 27min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 4Ô∏è‚É£ Generate text üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "### 4.1) Generation model ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to edit our model for generation, the code below looks excessive so lets break it down:\n",
    "\n",
    "- We will inherit from Keras base model and pass our previously defined model to the `__init__` method\n",
    "- We will also create a mask which add a value of **negative infinity** for the unknown character **`[UNK]`** used to denote characters outside of our vocab as we never want our model to generate this character.\n",
    "- We **sample** and **squeeze** to get the predicted ids.\n",
    "- We pass the state back to allow us to feed it back into the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:34:54.175589Z",
     "iopub.status.busy": "2022-12-14T13:34:54.175313Z",
     "iopub.status.idle": "2022-12-14T13:34:54.183593Z",
     "shell.execute_reply": "2022-12-14T13:34:54.182961Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "### 4.2) Using the model üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9yDoa0G3IgQ"
   },
   "source": [
    "Now we can run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences but pretty impressive for the training time! üôå"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Play around with the input text and the number of predict characters and see what your model creates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:34:54.205117Z",
     "iopub.status.busy": "2022-12-14T13:34:54.204676Z",
     "iopub.status.idle": "2022-12-14T13:34:56.855564Z",
     "shell.execute_reply": "2022-12-14T13:34:56.854833Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juliet: Where art thou, Romeo?\n",
      "\n",
      "RICANTIO:\n",
      "What altious to's visies. What way not, the loss\n",
      "of covestarinem, Shall for the king him of the mine,\n",
      "And in thy hangs of our book's whither will; not the\n",
      "king, are; which that for ghatters ouchs\n",
      "For this else all Post.\n",
      "\n",
      "LEONTES:\n",
      "O, hastand, mary fear, bless, with pulf'st, I\n",
      "it were present our searest,\n",
      "Thou shall deliver, sir, a country sprovett, and approof,\n",
      "To wail quarrets, that else that I am sunder, fatten: I that I did stal:\n",
      "How onfucion day to his son, Is our grace,\n",
      "Are king'st, thy feach yet: still have well to knew them arries;\n",
      "Pinces a fair prefection tears honour enemy.\n",
      "Mustanous my astilife: I had your long as well:\n",
      "For thou thy sea light would one, what thou?\n",
      "\n",
      "Buttern:\n",
      "Shiuste. I am sound\n",
      "And a helprow to better to hin theirech, nameing in\n",
      "Here is curto fie give some can seen to comfort, or a sin\n",
      "For with for our lovidius, I have no demand:\n",
      "I think it evis us a word, I show me,\n",
      "Inceise, yet all the friars, by the city or in his hisses:\n",
      "Vorthing them woos that  \n",
      "\n",
      "________________________________________________________________________________\n",
      "CPU times: user 2.73 s, sys: 133 ms, total: 2.86 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "states = None\n",
    "next_char = tf.constant(['Juliet: Where art thou, Romeo?'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "üèÅ Even though the results could be improved significantly it is quite incredible what the model learnt in **only five** epochs! Next you can up the epochs or try using the model on some text of your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t09eeeR5prIJ"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T13:32:11.928547Z",
     "iopub.status.busy": "2022-12-14T13:32:11.927961Z",
     "iopub.status.idle": "2022-12-14T13:32:11.931971Z",
     "shell.execute_reply": "2022-12-14T13:32:11.931377Z"
    },
    "id": "GCCk8_dHpuNf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
